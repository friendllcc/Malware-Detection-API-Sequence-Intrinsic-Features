import os
import numpy as np
import pandas as pd
from keras.preprocessing import sequence
from keras.layers.embeddings import Embedding
from keras.layers import Dense, LSTM, Bidirectional, Dropout, Conv1D, concatenate
from keras.layers import Dense, Flatten, Dropout, GlobalMaxPooling1D, BatchNormalization
from keras.models import Sequential, load_model, Model
from keras import regularizers, Input
from keras.optimizers import Adam
from keras.callbacks import Callback
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score

# specify which GPU will be used
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# some hyper-parameter
class Config(object):
    data_length = 1000
    embedding_output_dim = 16
    embedding_output_dim_semantic = 8
    CNN_filters = 128
    LSTM_units = 100
    DNN_size1 = 64
    DNN_size2 = 32
    dropout_rate = 0.2
    epochs = 35
    batch_size = 50


# calculate and record scores
class Metrics(Callback):
    train_x_name = []
    train_x_semantic = []
    train_y = []

    test_x_name = []
    test_x_semantic = []
    test_y = []

    def __init__(self, train_x_name, train_x_semantic, train_y, test_x_name, test_x_semantic, test_y):
        self.train_x_name = train_x_name
        self.train_x_semantic = train_x_semantic
        self.train_y = train_y

        self.test_x_name = test_x_name
        self.test_x_semantic = test_x_semantic
        self.test_y = test_y

    def on_train_begin(self, logs={}):
        self.scores = {'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_f1': [],
                       'val_confusion_matrix': []}
        self.test_scores = {'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_f1': [],
                            'val_confusion_matrix': []}

    def on_epoch_end(self, epoch, logs={}):
        # record the scores after each epoch
        val_predict = np.asarray(self.model.predict([self.train_x_name, self.train_x_semantic])).round()  ##.model
        val_targ = self.train_y
        _val_acc = accuracy_score(val_targ, val_predict)
        _val_recall = recall_score(val_targ, val_predict)
        _val_precision = precision_score(val_targ, val_predict)
        _val_f1 = f1_score(val_targ, val_predict)
        _val_confusion_matrix = confusion_matrix(val_targ, val_predict)
        self.scores['val_accuracy'].append(_val_acc)
        self.scores['val_precision'].append(_val_precision)
        self.scores['val_recall'].append(_val_recall)
        self.scores['val_f1'].append(_val_f1)
        self.scores['val_confusion_matrix'].append(_val_confusion_matrix)
        print("\n-val_acc: {} — val_precision: {} — val_recall: {} — val_f1:{}".format(_val_acc, _val_precision,
                                                                                       _val_recall, _val_f1))
        return


# return the model
def create_model(data_length, embedding_output_dim, embedding_output_dim_semantic, CNN_filters, LSTM_units,
                 dropout_rate, DNN_size1, DNN_size2):
    # Model Input
    train_x_name = Input(shape=(data_length,), dtype='float64', name='train_x_name')
    train_x_semantic = Input(shape=(data_length * 4,), dtype='float64', name='train_x_semantic')  # Semantic Chain

    # Word Embedding
    embedder1 = Embedding(input_dim=316, output_dim=embedding_output_dim, input_length=data_length)
    embedder2 = Embedding(input_dim=289, output_dim=embedding_output_dim_semantic, input_length=data_length * 4)

    embed1 = embedder1(train_x_name)
    embed2 = embedder2(train_x_semantic)

    # API Phrase Feature Maps: three convolution layers with filter size h = 3, 4, 5
    cnn1_1 = Conv1D(filters=CNN_filters, kernel_size=3, padding='same', strides=1, activation='relu')(embed1)
    cnn1_2 = Conv1D(filters=CNN_filters, kernel_size=4, padding='same', strides=1, activation='relu')(embed1)
    cnn1_3 = Conv1D(filters=CNN_filters, kernel_size=5, padding='same', strides=1, activation='relu')(embed1)

    # Semantic Chain Feature Maps
    cnn2 = Conv1D(filters=CNN_filters, kernel_size=4, padding='same', strides=4, activation='relu')(embed2)

    # Feature Concatenate
    con = concatenate([cnn1_1, cnn1_2, cnn1_3, cnn2], axis=-1)

    # Bi-LSTM
    lstm = Bidirectional(LSTM(units=LSTM_units, return_sequences=True, activation='sigmoid'))(con)
    flat = Flatten()(lstm)

    # Classification
    drop = Dropout(dropout_rate)(flat)
    dnn1 = Dense(DNN_size1, activation='relu')(drop)
    drop2 = Dropout(dropout_rate)(dnn1)
    dnn2 = Dense(DNN_size2, activation='relu')(drop2)
    main_output = Dense(1, activation='sigmoid')(dnn2)

    model = Model(inputs=[train_x_name, train_x_semantic], outputs=main_output)
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=None)  # optimizer='adam'
    model.summary()
    return model


# load data
def get_data():
    data = np.load('./data.npz', allow_pickle=True)
    train_x_name = data['train_x_name']  # API sequences index for training
    train_x_semantic = data['train_x_semantic']  # semantic chain index for training
    train_y = data['train_y']  # label for training
    test_x_name = data['test_x_name']  # API sequences index for test
    test_x_semantic = data['test_x_semantic']  # semantic chain index for test
    test_y = data['test_y']  # label for test
    train_MD5 = data['train_MD5']  # training samples' MD5 index
    test_MD5 = data['test_MD5']  # test samples' MD5 index
    return train_x_name, train_x_semantic, train_y, test_x_name, test_x_semantic, test_y


train_x_name, train_x_semantic, train_y, test_x_name, test_x_semantic, test_y = get_data()
metric = Metrics(train_x_name, train_x_semantic, train_y, test_x_name, test_x_semantic, test_y)

model = create_model(
    Config.data_length,
    Config.embedding_output_dim,
    Config.embedding_output_dim_semantic,
    Config.CNN_filters,
    Config.LSTM_units,
    Config.dropout_rate,
    Config.DNN_size1,
    Config.DNN_size2)

model.fit([train_x_name, train_x_semantic],
          train_y,
          batch_size=Config.batch_size,
          epochs=Config.epochs,
          callbacks=[metric])

# model.save('model.h5')
